{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIQeLiHIxHJ5Uup8EyAJ55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrielasants7/NLP2/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento de Texto com TensorFlow\n",
        "\n",
        "Este notebook demonstra como realizar o pré-processamento de texto usando a biblioteca TensorFlow em Python, especificamente a camada `TextVectorization`. O objetivo é criar um vocabulário a partir de um conjunto de sentenças e associar cada palavra a um índice numérico.\n",
        "\n",
        "*Esse projeto faz parte do curso Stanford University |\n",
        "DeepLearning.AI Programa de cursos integrados Aprendizado de máquina\n",
        "Aprendizado não supervisionado, recomendações, aprendizado por reforço*\n",
        "\n",
        "## Como funciona\n",
        "\n",
        "1. **Importar bibliotecas:** Importa as bibliotecas necessárias, incluindo `tensorflow` para funcionalidades de aprendizado de máquina e `IPython` para interação com o ambiente do notebook.\n",
        "\n",
        "2. **Definir sentenças:** Define uma lista de sentenças de exemplo que serão usadas para construir o vocabulário. Essas sentenças são sobre filmes e séries.\n",
        "\n",
        "3. **Criar a camada de vetorização:** Inicializa uma camada `TextVectorization` do TensorFlow. Essa camada é responsável por converter texto em vetores numéricos.\n",
        "\n",
        "4. **Adaptar ao vocabulário:** A camada de vetorização é \"adaptada\" às sentenças de entrada usando o método `adapt()`. Isso significa que a camada analisa as sentenças e constrói um vocabulário com base nas palavras únicas encontradas.\n",
        "\n",
        "5. **Obter o vocabulário:** O vocabulário é extraído da camada de vetorização usando o método `get_vocabulary()`. O argumento `include_special_tokens=False` garante que tokens especiais (como padding e unknown) não sejam incluídos no vocabulário.\n",
        "\n",
        "6. **Imprimir o vocabulário:** O código itera pelo vocabulário e imprime cada palavra junto com seu índice numérico correspondente.\n",
        "\n",
        "\n",
        "## Uso\n",
        "\n",
        "Para executar este código, você precisa ter o TensorFlow instalado. Você pode instalá-lo usando `pip install tensorflow`.\n",
        "\n",
        "1. Copie e cole o código em um notebook do Google Colab ou em um arquivo Python.\n",
        "2. Execute o código.\n",
        "3. O vocabulário será impresso no console, mostrando cada palavra e seu índice.\n",
        "\n",
        "\n",
        "## Observações\n",
        "\n",
        "- O vocabulário resultante é uma lista onde as palavras mais frequentes têm índices menores.\n",
        "- Este código é um exemplo básico de pré-processamento de texto. Em aplicações reais, você pode precisar realizar etapas adicionais, como limpeza de texto, remoção de stop words e stemming/lemmatization.\n",
        "\n",
        "\n",
        "## Próximos passos\n",
        "\n",
        "Este código pode ser usado como base para construir modelos de aprendizado de máquina que trabalham com dados de texto. Por exemplo, você pode usar o vocabulário gerado para converter sentenças em vetores numéricos e usá-los como entrada para um modelo de classificação de texto."
      ],
      "metadata": {
        "id": "AxxD2fLweYou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9aTcaqheVfM"
      },
      "outputs": [],
      "source": [
        "#importando as bibliotecas\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definindo a lista de sentenças (frases) que serão usadas como entrada para o processo de vetorização\n",
        "sentencas = [\n",
        "    \"Breaking Bad é uma das melhores séries de todos os tempos\",\n",
        "    \"Adoro maratonar séries no fim de semana\",\n",
        "    \"Qual seu filme favorito da Marvel?\",\n",
        "    \"A atuação em O Poderoso Chefão é impecável\",\n",
        "    \"Friends ainda é uma série muito divertida\",\n",
        "    \"Game of Thrones teve um final controverso\",\n",
        "    \"Já assistiu Stranger Things? É incrível!\",\n",
        "    \"Os filmes de Christopher Nolan sempre têm roteiros complexos\",\n",
        "    \"O suspense em Parasita foi muito bem construído\",\n",
        "    \"A nova temporada de The Witcher foi muito aguardada pelos fãs\"\n",
        "]\n",
        "\n",
        "\n",
        "#inicializndo a camada de vetorização\n",
        "\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "\n",
        "#construção do vocabulário\n",
        "#adapt é chamado com as sentenças como entrada. Esse método analisa as sentenças\n",
        "# e constrói um vocabulário com base nas palavras encontradas nos dados fornecidos\n",
        "vectorize_layer.adapt(sentencas)\n",
        "\n",
        "#obtençõo do vocabulário\n",
        "\n",
        "vocabulario = vectorize_layer.get_vocabulary(include_special_tokens=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "RE6q9BiRepDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O vocabulário resultante será uma lista onde as palavras usadas com mais frequência terão um índice mais baixo. Por padrão, ele também reservará índices para tokens especiais"
      ],
      "metadata": {
        "id": "nzHup4yqg8E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printando o indice  token\n",
        "for index, word in enumerate(vocabulario):\n",
        "  print(index, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOm_Z7cBg8vJ",
        "outputId": "79ec45aa-f7b6-4b74-c29d-36442539fbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 de\n",
            "1 é\n",
            "2 muito\n",
            "3 uma\n",
            "4 séries\n",
            "5 os\n",
            "6 o\n",
            "7 foi\n",
            "8 em\n",
            "9 a\n",
            "10 É\n",
            "11 witcher\n",
            "12 um\n",
            "13 têm\n",
            "14 todos\n",
            "15 thrones\n",
            "16 things\n",
            "17 the\n",
            "18 teve\n",
            "19 tempos\n",
            "20 temporada\n",
            "21 série\n",
            "22 suspense\n",
            "23 stranger\n",
            "24 seu\n",
            "25 sempre\n",
            "26 semana\n",
            "27 roteiros\n",
            "28 qual\n",
            "29 poderoso\n",
            "30 pelos\n",
            "31 parasita\n",
            "32 of\n",
            "33 nova\n",
            "34 nolan\n",
            "35 no\n",
            "36 melhores\n",
            "37 marvel\n",
            "38 maratonar\n",
            "39 já\n",
            "40 incrível\n",
            "41 impecável\n",
            "42 game\n",
            "43 fãs\n",
            "44 friends\n",
            "45 final\n",
            "46 fim\n",
            "47 filmes\n",
            "48 filme\n",
            "49 favorito\n",
            "50 divertida\n",
            "51 das\n",
            "52 da\n",
            "53 controverso\n",
            "54 construído\n",
            "55 complexos\n",
            "56 christopher\n",
            "57 chefão\n",
            "58 breaking\n",
            "59 bem\n",
            "60 bad\n",
            "61 atuação\n",
            "62 assistiu\n",
            "63 ainda\n",
            "64 aguardada\n",
            "65 adoro\n"
          ]
        }
      ]
    }
  ]
}